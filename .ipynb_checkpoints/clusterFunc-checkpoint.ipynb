{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import warnings \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from getUserStudyModel import getModel\n",
    "#userModel=getModel()\n",
    "\n",
    "userModel = pd.read_csv('fully_study_model.csv', sep=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "userModel=userModel.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning:\n",
      "\n",
      "numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning:\n",
      "\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataWithOutliers=userModel.loc[:,['problem_duration_graded','problem_duration_ungraded','video_duration']]\n",
    "from sklearn.ensemble import IsolationForest\n",
    "clfOutliers = IsolationForest()\n",
    "clfOutliers.fit(dataWithOutliers)\n",
    "isOutlier = clfOutliers.predict(dataWithOutliers)\n",
    "isOutlier=pd.DataFrame(isOutlier)\n",
    "isOutlier=userModel.join(isOutlier)\n",
    "userModel=isOutlier.loc[isOutlier[0]==1]\n",
    "userModel=userModel.reset_index()\n",
    "userModel=userModel.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "userModel.to_csv('fully_study_model.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(userModel):\n",
    "\n",
    "    #X=userModel.loc[userModel['theme_id']=='e3c0abd8380d446c8e9a5fb6b15aeefc']\n",
    "    X=userModel\n",
    "    X=X.loc[:,['problem_duration_graded','problem_duration_ungraded','video_duration']]    \n",
    "    \n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    #X = MinMaxScaler().fit_transform(X)\n",
    "    #X = scale(X) \n",
    "    \n",
    "    \n",
    "    floatArr=[i for i in np.arange(0.1,1.1,0.1)]\n",
    "    intArr=[i for i in range(2,15)]\n",
    "    \n",
    "    \n",
    "    #eps float and minsamples int\n",
    "    algorithm=cluster.DBSCAN()   \n",
    "    \n",
    "    #eigen_tol float and n_clusters int (optional)\n",
    "    #algorithm=cluster.SpectralClustering() \n",
    "    \n",
    "    #n_clusters int\n",
    "    #algorithm=cluster.AgglomerativeClustering()\n",
    "    \n",
    "    #n_clusters int and batch_size int\n",
    "    #algorithm=cluster.MiniBatchKMeans()\n",
    "    \n",
    "    #dim=3\n",
    "    #dim=2\n",
    "    \n",
    "    coords=[]\n",
    "    \n",
    "    for para1 in floatArr:\n",
    "    #for para1 in intArr:\n",
    "        for para2 in intArr:\n",
    "            silhouette,time,clusters_num=clusteringParams(X,para1,para2,algorithm)            \n",
    "            coords.append((para1,para2,silhouette,time,clusters_num))\n",
    "    \"\"\"\n",
    "    for para1 in intArr:\n",
    "        silhouette,time,clusters_num=clusteringParams(X,para1,0,algorithm)\n",
    "        coords.append((para1,silhouette,time))\n",
    "    \"\"\"\n",
    "        \n",
    "            \n",
    "    return coords,3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusteringParams(X,para1,para2,algorithm):\n",
    "\n",
    "    algorithm.set_params(eps=para1, min_samples=para2) #dbscan\n",
    "    #algorithm.set_params(n_clusters=para2,eigen_tol=para1) #spectural\n",
    "    #algorithm.set_params(n_clusters=para1) #agglomerative\n",
    "    #algorithm.set_params(n_clusters=para1,batch_size=para2) #k-means\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=\"the number of connected components of the \" +\n",
    "            \"connectivity matrix is [0-9]{1,2}\" +\n",
    "            \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "            category=UserWarning)\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=\"Graph is not fully connected, spectral embedding\" +\n",
    "            \" may not work as expected.\",\n",
    "            category=UserWarning)\n",
    "        algorithm.fit(X)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    labels_num=len(np.unique(algorithm.labels_))\n",
    "\n",
    "    if len(np.unique(algorithm.labels_))>1:\n",
    "        silhouette=silhouette_score(X,labels=algorithm.labels_)        \n",
    "    else:\n",
    "        silhouette=-1\n",
    "       \n",
    "    return silhouette, (t1-t0) , labels_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords,dim=clustering(userModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.DataFrame(coords, columns=['para1','para2','silhouette','time','clusters_num'])\n",
    "#tmp=pd.DataFrame(coords, columns=['para1','silhouette','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCoef=max(list(tmp['silhouette']))\n",
    "maxCoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=tmp.loc[tmp['silhouette']==maxCoef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minTime=min(list(t['time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=t.loc[t['time']==minTime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metricPlot(coords,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#скорость работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "userModel = pd.read_csv('problems_starts_time.csv', sep=',', encoding='utf-8')\n",
    "#problems_starts_time\n",
    "X=userModel.loc[:,['problem_duration_graded','problem_duration_ungraded','messagiesNum','video_duration']]    \n",
    "X = StandardScaler().fit_transform(X)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "algorithm1=cluster.DBSCAN(eps=1.0, min_samples=3)\n",
    "algorithm2=cluster.SpectralClustering(n_clusters=3,eigen_tol=0.9)\n",
    "algorithm3=cluster.AgglomerativeClustering(n_clusters=2)\n",
    "algorithm4=cluster.MiniBatchKMeans(n_clusters=2,batch_size=5)\n",
    "\n",
    "algorithms=[algorithm1,algorithm2,algorithm3,algorithm4]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "algotime=[]\n",
    "pointsX=[]\n",
    "for algorithm in algorithms:\n",
    "    tmpAlgoTime=[]\n",
    "    for dataPercent in range(10,101,10):\n",
    "        size=round(X.shape[0]*dataPercent/100)\n",
    "        if len(pointsX)<10:\n",
    "            pointsX.append(size)\n",
    "        tmpX=X[0:size]\n",
    "        silhouette, wtime = clusteringParams(tmpX,0,0,algorithm)\n",
    "        tmpAlgoTime.append(wtime)\n",
    "    algotime.append(tmpAlgoTime)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.DataFrame(algotime).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "names = ['DBSCAN','Spectral Clustering','Agglomerative clustering','K-means']\n",
    "\n",
    "data=[]\n",
    "for algoNum in range(df.shape[1]):\n",
    "    Y=df[algoNum]\n",
    "    data.append(\n",
    "        go.Scatter(\n",
    "            x=pointsX,\n",
    "            y=Y,\n",
    "            mode='markers+lines',\n",
    "            marker=dict(size=5),\n",
    "            name=names[algoNum]\n",
    "        )   \n",
    "    )\n",
    "\n",
    "\n",
    "layout = go.Layout(        \n",
    "        xaxis=dict(title='Количество данных для обучения',ticklen= 5, showticklabels=True),\n",
    "        yaxis=dict(title='Время, потраченное на обучение (в секундах)',ticklen= 5,zeroline= True,showticklabels=True),\n",
    "    legend=dict(x=0.01, y=1)\n",
    "    \n",
    "    )\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, world_readable=True, filename='specStudyModel')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#основные кластеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Поменять параметры в моделях для конкретной задаче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm1=cluster.DBSCAN(eps=1.0, min_samples=3)\n",
    "algorithm2=cluster.SpectralClustering(n_clusters=3,eigen_tol=0.9)\n",
    "algorithm3=cluster.AgglomerativeClustering(n_clusters=2)\n",
    "algorithm4=cluster.MiniBatchKMeans(n_clusters=2,batch_size=5)\n",
    "\n",
    "algorithms=[algorithm1,algorithm2,algorithm3,algorithm4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#userModel = pd.read_csv('problems_starts_time.csv', sep=',', encoding='utf-8')\n",
    "#problems_starts_time\n",
    "models=userModel.loc[:,['problem_duration_graded','problem_duration_ungraded','messagiesNum','video_duration']]    \n",
    "scal = StandardScaler()\n",
    "X_t = scal.fit_transform(X)\n",
    "\n",
    "#centers=scal.inverse_transform(algorithm3.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm4=cluster.MiniBatchKMeans(n_clusters=8,batch_size=12)\n",
    "algorithm4.fit(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X=userModel.loc[:,['problem_duration_graded','problem_duration_ungraded','video_duration']]\n",
    "X = scale(X) \n",
    "algorithm2.fit(X)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "scale_features = MinMaxScaler() \n",
    "X=userModel.loc[:,['problem_duration_graded','problem_duration_ungraded','messagiesNum','video_duration']]  \n",
    "features_train = scale_features.fit_transform(X) \n",
    "algorithm1.fit(features_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers=scal.inverse_transform(algorithm4.cluster_centers_)\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(algorithm4.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.DataFrame(algorithm4.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledModel=userModel.join(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forcalc=labeledModel.loc[labeledModel[0]==0]\n",
    "minimum=labeledModel.groupby(0)['problem_duration_graded','problem_duration_ungraded','video_duration'].min()\n",
    "maximum=labeledModel.groupby(0)['problem_duration_graded','problem_duration_ungraded','video_duration'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricPlot(coords,dim):\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        line=dict(\n",
    "            color='rgb(0, 0, 0)',\n",
    "            width=0.5\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if dim==3:\n",
    "        tmp=pd.DataFrame(coords, columns=['para1','para2','coefficient','time','cluster_num'])\n",
    "        X=tmp['para1']\n",
    "        Y=tmp['para2']\n",
    "        Z=tmp['coefficient']\n",
    "        #text=\"time: \"+ str(tmp['time'])+\", clusters: \"+ str(tmp['cluster_num'])\n",
    "        \n",
    "        trace = go.Scatter3d(\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            z=Z,\n",
    "            text=tmp['cluster_num'],\n",
    "            mode='markers',\n",
    "            marker=marker\n",
    "        )\n",
    "    else:\n",
    "        tmp=pd.DataFrame(coords, columns=['para1','coefficient','time'])\n",
    "        X=tmp['para1']\n",
    "        Y=tmp['coefficient']\n",
    "        text=tmp['time']\n",
    "        \n",
    "        trace = go.Scatter(\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            text=text,\n",
    "            mode='markers',\n",
    "            marker=marker\n",
    "        )         \n",
    "\n",
    "    data = [trace]\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        ),\n",
    "        scene = dict(\n",
    "        xaxis=dict(title='eps'),\n",
    "        yaxis=dict(title='min_samples'),\n",
    "        zaxis=dict(title='silhouette')\n",
    "        )\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig, world_readable=True, filename='dbscan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker=dict(\n",
    "    size=5,\n",
    "        line=dict(\n",
    "            color='rgb(0, 0, 0)',\n",
    "            width=0.5\n",
    "        )\n",
    ")\n",
    "        \n",
    "trace = go.Scatter3d(\n",
    "    x=tmp['para1'],\n",
    "    y=tmp['para2'],\n",
    "    z=tmp['silhouette'],\n",
    "    text=tmp['clusters_num'],\n",
    "    mode='markers',\n",
    "    marker=marker\n",
    ")\n",
    "data = [trace]\n",
    "    \n",
    "layout = go.Layout(\n",
    "    margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "    ),\n",
    "    scene = dict(\n",
    "        xaxis=dict(title='eps'),\n",
    "        yaxis=dict(title='min_samples'),\n",
    "        zaxis=dict(title='silhouette')\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, world_readable=True, filename='dbscan')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
